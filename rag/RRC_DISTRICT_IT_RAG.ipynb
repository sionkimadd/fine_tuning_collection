{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZuiAtYrnf3b",
    "outputId": "f4c35187-5091-41ae-8490-e13f37a3a8d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "major_version, minor_version = torch.cuda.get_device_capability()\n",
    "major_version, minor_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkwWxI6xrZL9"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435,
     "referenced_widgets": [
      "111e67ba7fa0475789c72fdff4bbe2f4",
      "a931c2b3ae824179a7efe8339cc88348",
      "2eb4121630b248c089e46b3f5b540927",
      "58241a428ae845289e5b673096ed74ea",
      "9ad2befb003448f68f67c57bdd94fcbf",
      "24804d17f49e400d840115bd83fda42b",
      "cb6847ae25d04cebbcf526e9a9950b19",
      "b4bf9b334e8f4f6e932cdd443818cfbc",
      "5b58104b37954a228e518f119263c49a",
      "ed205148367247f6a3b21d97a2404d18",
      "a50d507a790a49a1bfa587e4d0d4bb94",
      "34119a8594b44b2684de8d3694e657fc",
      "66827923444c460c8102b883dbfbc8d5",
      "5f5cda4325a1478ebdeefc00f0f29a9e",
      "73cfc6d286164fe1900c9fa653a70107",
      "04b7b983cf22401391d10461706b3e81",
      "baf1e4e4bd1f4ad595d97bccfbb7542b",
      "f128548873874225b9ab191bbaffa80f",
      "2142f3007052412c92d1e447770ca1c1",
      "7ef7b41095ba4ee49bb8d9d57baddf07",
      "1e12d4ca2fec4ed3b2130597526b24de",
      "cc5a2f872e5046bca4df0209ee983ecb",
      "a7745e3c89ce4e35bb50febacc22160e",
      "a55a8bff197b4e41a908570af5cd1655",
      "973beaeab43a403d9234e92a6712ca58",
      "4a66d53a64224f139dd42725f3b064df",
      "21f02a4030754a1ea65540cff5ab54f7",
      "9f1e99cc44d2418f992c4feb8ca19b7a",
      "1991889faa4445ed94cba6dae560bd28",
      "994c990a2157462490064411aa481f31",
      "53f347c40bc443a19566f6ab8aa9798b",
      "b5e49bbafc104a7a88c83e4d793c0388",
      "7d813fb2f8ad48d5b592267dd3856fbd",
      "5b0e2b7e6ab24cdf91a95aa8a54dda51",
      "0c89fa9753324f7da41c578a00a5fd30",
      "d1a79b5917bc4104a11a7009a38c31ed",
      "a2b9e7627f1a46cfbcfe7b63ecbb9778",
      "f83fdaf10fff44d6a3de0ee5403bce1b",
      "28e63996f518490eb3586b74291439f1",
      "f17fe587f6c94bbeb26a0e1e94c86372",
      "c42ab6a6b5ca4a36a9cdbdb52943e82c",
      "e70cc42960b342249a5bc658819214a9",
      "d8a6dea0659b42d6a8a2faa3a04880c4",
      "9e05e921ca8f4fae81e68c8864981e57",
      "49af757f731f427594f6c9e66193ae3b",
      "142a31ebde6a4b18ac01e53a91f816ad",
      "c1bb16c8d122400da0bd6b01b79f8393",
      "f3f630f1d89a4e2f88abb67ce829ac08",
      "406c8bfde6d444149f2347998ec69262",
      "f69d5ad859c747899ddb20bc841839bd",
      "e6784b619b51407d885a246fd12797a1",
      "df38f16f1c2e467f807a5a8f0a707e11",
      "7726c98bd8bc41a5b7eb151d458b8296",
      "a078bbaa5d85485d9a545a7091008f47",
      "ff0e71c0acf64b54917bb90ffb746c9a"
     ]
    },
    "id": "kGftk8MlsXGb",
    "outputId": "4e7e9261-b6fd-437c-ce0a-5a449ab9dd94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ε Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.6.0+cu124)\n",
      "    Python  3.11.12 (you have 3.11.13)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ε Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.6.1: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111e67ba7fa0475789c72fdff4bbe2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34119a8594b44b2684de8d3694e657fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/198 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7745e3c89ce4e35bb50febacc22160e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0e2b7e6ab24cdf91a95aa8a54dda51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49af757f731f427594f6c9e66193ae3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 4096\n",
    "\n",
    "dtype = None\n",
    "\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzRc41PZtPjG",
    "outputId": "30a55829-d642-4ae5-bf72-94f18120f23d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.6.1 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=42,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "47362eabd683428ea670f3525c9cd61b",
      "087b5ea3b5c640a58e8474d7b5cbe2e8",
      "9b2b6519a7ac4683b3e3d6c38eb28b6c",
      "3cd0225a0d3f4f429460ece97359ef44",
      "0ad7521262f1416b8f17eaf679d77b61",
      "0b47cfe181bf4af2a2727ed71f7c2d2f",
      "09af949ef1cb4f078e74669ab26473f2",
      "f300ebb4998e4c279e75e58c54a0eb32",
      "216d71040ea34a80b044326d489787e3",
      "e853b1a055704e84bcb30a24f4c71ab5",
      "c55e2fecfbdc435ea4e4600f84353e38",
      "5d99c419c89e4be28e935905e392ab5f",
      "5c0b78740fe34c8aa8483d7cf8bbd5ab",
      "9c7d28f858ed4944a4cc306e5163beb5",
      "27e584d129274ed692c240c1b0e010a9",
      "42f3bba14a954a59b1fcd3c400ad73e4",
      "e28973ef40924ad493070a61b9cc6d87",
      "d755c3905a9b4c0bab8d8bd60b355aa5",
      "6da10b8889164b4d9d087503eacbc2be",
      "a2a56810ba544c7cb9d641f369455e3d",
      "f16d1f30cfbb4f0f8699d36aa07b2e13",
      "195b9cf402b944e7b1ac2f253ee83938",
      "24f7f865dc644f618f96d43a5da74f56",
      "d259134fb2d84453928f4c3ebf2ccc5c",
      "cf48f08f1d5c480ebf90812348e2a141",
      "d181a67ded00407582c7d35f4fff060c",
      "ed0dc9e314aa454d9ca1d4cd5a0e67d0",
      "a76310b0fc1f4935800c724028c82e52",
      "0ea3f61981d04ac3b848944a59ce25e9",
      "e458dc29df784b08a2500cd65c3ac7d2",
      "34387e7d1614416aa4abaebfaa4cf05a",
      "38afe9cc52754b43bfd513dff0da6e3b",
      "eb1d951b8e8c47979f6146eec2d9d048",
      "1d2f26498b474924af10f732352d4efb",
      "e94b2e401d2344c7aae5345975d3b38f",
      "6071dc2609df4a389ad4d2574c032d70",
      "2e60a29b3595440db9f5b35b63a2b2fa",
      "fc9a611c34c6464c9deef5ceb4e963f4",
      "855254b4337045cf82c701aedc12b5f4",
      "d414fdc3317f4196a5d4bcbb9c627a61",
      "1831e2d088e34f46a137bbeb0b2ff541",
      "4e51f4fa139e47aa869b17bab45a7824",
      "5fbd2d8d76b443ee883a175f485baa32",
      "2753140719b74918a045128209f45d92"
     ]
    },
    "id": "Le8gx2p1uHd5",
    "outputId": "83bba31d-654b-4425-fa87-932e6dc1f010"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47362eabd683428ea670f3525c9cd61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d99c419c89e4be28e935905e392ab5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/139k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f7f865dc644f618f96d43a5da74f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2f26498b474924af10f732352d4efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,\n",
    "    }\n",
    "\n",
    "dataset = load_dataset(\"logicalqubit/QA-RRC-DISTRIC-IT\", split=\"train\")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e0cb2cfa69ac4cf1bda7fab8f107b7b4",
      "25fbb79908d942c4821e246268778f0a",
      "b12c79fa178c48cc8bd52dcc6d865b5e",
      "37a6c32a1ab646069fa225f615dda8fa",
      "1957a74ebacb4695abdbe4ddcb1161c5",
      "3f4102b9755d4daca57305dba994dd73",
      "f8fcf1cbe4914f2587868bb531f2dbcb",
      "1b4c76b9fc4b46d1a746809e2cd4595f",
      "316f3cd5681247489cdcdc714a11cc2a",
      "62086119244846b29db00cc49ad2ef6f",
      "a3c5776fd390492b9204ca492cb80a6c",
      "6a039ec286b94ef79fdd35c54775119e",
      "2f8279b5c9874c55873a62ef875ad0cb",
      "35c3f10290a741a6858a814e1a6089a4",
      "dd5fc7f7c1364921bf99569ecd8a191f",
      "1c64f0da12b646d6a21aec975031ef2d",
      "045bc1140fda4bbab482b49903988cb1",
      "6e46a98685a44fff9bcc1dc862b92d3c",
      "a581ea9b77d84204bdd5a4a1f46ba1f2",
      "d47de56ce740408eb12fd2deb6434bb5",
      "3bffd3ca4a5042bcabd5a9bf99a6a1df",
      "b0d40fd5561449aeb196f6333a7fbc4d"
     ]
    },
    "id": "7-KaETTivxfH",
    "outputId": "bcbf4ae8-f2dc-4e55-ae63-ca4ecf8ed68b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cb2cfa69ac4cf1bda7fab8f107b7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/1520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a039ec286b94ef79fdd35c54775119e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/1520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=40,\n",
    "        logging_steps= 10,\n",
    "        learning_rate=2e-5,\n",
    "        fp16=not torch.cuda.is_bf16_supported(),\n",
    "        bf16=torch.cuda.is_bf16_supported(),\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        seed=42,\n",
    "        output_dir=\"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l0YSiZhSxg_e",
    "outputId": "8f1f695f-bd5c-4d56-b791-96f7c0df181e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,520 | Num Epochs = 40 | Total steps = 7,600\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 83,886,080/8,000,000,000 (1.05% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 路路路路路路路路路路\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlogicalqubit\u001b[0m (\u001b[33mlogical-qubit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250606_210939-0mqphuk8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/logical-qubit/huggingface/runs/0mqphuk8' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/logical-qubit/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/logical-qubit/huggingface' target=\"_blank\">https://wandb.ai/logical-qubit/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/logical-qubit/huggingface/runs/0mqphuk8' target=\"_blank\">https://wandb.ai/logical-qubit/huggingface/runs/0mqphuk8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7600' max='7600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7600/7600 5:02:42, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.752900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.590900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.195600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.964100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.868200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.851100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.809800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.746800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.757600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.791500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.731300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.763200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.624400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.590200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.650500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.623700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.584300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.606400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.605800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.595800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.561700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.564200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.504600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.597300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.529900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.557700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.542100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.599300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.483300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.432200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.482600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.452700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.497700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.430700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.435600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.453900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.462100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.456200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.459400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.445800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.460900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.470600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.350600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.371700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.344400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.309100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.366900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.337900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.332600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.370500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.327100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.343300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.257300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.271600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.269000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.258400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.267300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.287400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.245800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.267400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.253900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.275800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.292900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.288500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.271500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.277600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.183800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.208600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.212300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.220900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.204200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.198700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.211100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.223700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.233800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.160900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.183200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.170300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.186200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.185800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.182100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.191900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.173700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.182900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.189800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.197600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.140600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.153400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.160100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.159100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.172700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.165900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.165700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.175600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.163600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.166400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.172300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.170600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.141400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.149400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.157700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.164700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.158600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.166800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.142200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.140200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.155100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.154500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.155100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>0.132700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.136900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.138800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>0.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>0.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.151500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>0.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>0.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.132200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>0.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.137400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>0.136400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>0.136600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>0.140700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.139200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.132200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>0.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>0.135800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>0.125800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>0.131400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>0.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>0.133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.132200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>0.134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>0.133100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>0.134100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>0.117700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>0.125700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>0.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.130300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>0.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>0.132400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>0.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.133300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.135500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>0.118300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>0.120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>0.123500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.125100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>0.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.125800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>0.125100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>0.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>0.130900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>0.134100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.132400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.133600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>0.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>0.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.118600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>0.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>0.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>0.116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.118800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>0.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>0.130600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>0.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.128400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>0.131300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>0.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>0.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.116300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>0.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>0.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>0.126800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>0.122100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3190</td>\n",
       "      <td>0.121700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>0.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3230</td>\n",
       "      <td>0.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>0.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3290</td>\n",
       "      <td>0.116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3310</td>\n",
       "      <td>0.119800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>0.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.116400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>0.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.120200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>0.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3430</td>\n",
       "      <td>0.112100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>0.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3470</td>\n",
       "      <td>0.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3490</td>\n",
       "      <td>0.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.115200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>0.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>0.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>0.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>0.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>0.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3590</td>\n",
       "      <td>0.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>0.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>0.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3630</td>\n",
       "      <td>0.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.108300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.116200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3710</td>\n",
       "      <td>0.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3730</td>\n",
       "      <td>0.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>0.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3770</td>\n",
       "      <td>0.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3790</td>\n",
       "      <td>0.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3810</td>\n",
       "      <td>0.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>0.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3830</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>0.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>0.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3870</td>\n",
       "      <td>0.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3890</td>\n",
       "      <td>0.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3910</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>0.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3930</td>\n",
       "      <td>0.118600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>0.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3970</td>\n",
       "      <td>0.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>0.117900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4010</td>\n",
       "      <td>0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4030</td>\n",
       "      <td>0.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>0.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4060</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4070</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>0.113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4090</td>\n",
       "      <td>0.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4110</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4120</td>\n",
       "      <td>0.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4130</td>\n",
       "      <td>0.113800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4160</td>\n",
       "      <td>0.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4170</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4180</td>\n",
       "      <td>0.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4190</td>\n",
       "      <td>0.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4210</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4220</td>\n",
       "      <td>0.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4230</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4240</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4270</td>\n",
       "      <td>0.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4290</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4310</td>\n",
       "      <td>0.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4330</td>\n",
       "      <td>0.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>0.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4360</td>\n",
       "      <td>0.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4370</td>\n",
       "      <td>0.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4390</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>0.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420</td>\n",
       "      <td>0.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4430</td>\n",
       "      <td>0.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>0.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4460</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4470</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4480</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4490</td>\n",
       "      <td>0.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.113800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4510</td>\n",
       "      <td>0.113900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4520</td>\n",
       "      <td>0.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4530</td>\n",
       "      <td>0.115400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4540</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4560</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4570</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4580</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4590</td>\n",
       "      <td>0.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4610</td>\n",
       "      <td>0.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4620</td>\n",
       "      <td>0.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4630</td>\n",
       "      <td>0.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4640</td>\n",
       "      <td>0.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4660</td>\n",
       "      <td>0.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4670</td>\n",
       "      <td>0.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4680</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4690</td>\n",
       "      <td>0.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4710</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4720</td>\n",
       "      <td>0.112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4730</td>\n",
       "      <td>0.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4740</td>\n",
       "      <td>0.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4760</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4770</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4780</td>\n",
       "      <td>0.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4790</td>\n",
       "      <td>0.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4810</td>\n",
       "      <td>0.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4820</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4830</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4840</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4860</td>\n",
       "      <td>0.112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4870</td>\n",
       "      <td>0.111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4880</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4890</td>\n",
       "      <td>0.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4910</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4920</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4930</td>\n",
       "      <td>0.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4940</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4960</td>\n",
       "      <td>0.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4970</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4980</td>\n",
       "      <td>0.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4990</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5010</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5020</td>\n",
       "      <td>0.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5030</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5040</td>\n",
       "      <td>0.109400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>0.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5060</td>\n",
       "      <td>0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5070</td>\n",
       "      <td>0.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5080</td>\n",
       "      <td>0.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5090</td>\n",
       "      <td>0.111500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5110</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5120</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5130</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5140</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5160</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5170</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5180</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5190</td>\n",
       "      <td>0.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5210</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5220</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5230</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5240</td>\n",
       "      <td>0.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5260</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5270</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5280</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5290</td>\n",
       "      <td>0.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5310</td>\n",
       "      <td>0.109400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5320</td>\n",
       "      <td>0.112400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5330</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5340</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5360</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5370</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5380</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5410</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5420</td>\n",
       "      <td>0.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5430</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5440</td>\n",
       "      <td>0.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>0.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5460</td>\n",
       "      <td>0.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5470</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5480</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5490</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5510</td>\n",
       "      <td>0.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5520</td>\n",
       "      <td>0.104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5530</td>\n",
       "      <td>0.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5540</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5560</td>\n",
       "      <td>0.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5570</td>\n",
       "      <td>0.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5580</td>\n",
       "      <td>0.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5590</td>\n",
       "      <td>0.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5610</td>\n",
       "      <td>0.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5620</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5630</td>\n",
       "      <td>0.109500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5640</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5660</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5670</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5680</td>\n",
       "      <td>0.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5690</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5710</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5720</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5730</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5740</td>\n",
       "      <td>0.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5760</td>\n",
       "      <td>0.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5770</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5780</td>\n",
       "      <td>0.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5790</td>\n",
       "      <td>0.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5810</td>\n",
       "      <td>0.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5820</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5830</td>\n",
       "      <td>0.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5840</td>\n",
       "      <td>0.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>0.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5860</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5870</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5880</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5890</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5910</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5920</td>\n",
       "      <td>0.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5930</td>\n",
       "      <td>0.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5940</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>0.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5960</td>\n",
       "      <td>0.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5970</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5980</td>\n",
       "      <td>0.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5990</td>\n",
       "      <td>0.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6010</td>\n",
       "      <td>0.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6020</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6030</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6040</td>\n",
       "      <td>0.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6060</td>\n",
       "      <td>0.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6070</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6080</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6090</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6110</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6120</td>\n",
       "      <td>0.108300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6130</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6140</td>\n",
       "      <td>0.104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6150</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6160</td>\n",
       "      <td>0.104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6170</td>\n",
       "      <td>0.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6180</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6190</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6210</td>\n",
       "      <td>0.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6220</td>\n",
       "      <td>0.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6230</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6240</td>\n",
       "      <td>0.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6260</td>\n",
       "      <td>0.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6270</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6280</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6290</td>\n",
       "      <td>0.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6310</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6320</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6330</td>\n",
       "      <td>0.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6340</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6350</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6360</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6370</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6380</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6390</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6410</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6420</td>\n",
       "      <td>0.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6430</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6440</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6450</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6460</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6470</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6480</td>\n",
       "      <td>0.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6490</td>\n",
       "      <td>0.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6510</td>\n",
       "      <td>0.100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6520</td>\n",
       "      <td>0.101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6530</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6540</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6550</td>\n",
       "      <td>0.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6560</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6570</td>\n",
       "      <td>0.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6580</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6590</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6610</td>\n",
       "      <td>0.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6620</td>\n",
       "      <td>0.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6630</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6640</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6650</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6660</td>\n",
       "      <td>0.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6670</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6680</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6690</td>\n",
       "      <td>0.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6710</td>\n",
       "      <td>0.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6720</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6730</td>\n",
       "      <td>0.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6740</td>\n",
       "      <td>0.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6760</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6770</td>\n",
       "      <td>0.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6780</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6790</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6810</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6820</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6830</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6840</td>\n",
       "      <td>0.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6850</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6860</td>\n",
       "      <td>0.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6870</td>\n",
       "      <td>0.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6880</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6890</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6910</td>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6920</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6930</td>\n",
       "      <td>0.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6940</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6950</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6960</td>\n",
       "      <td>0.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6970</td>\n",
       "      <td>0.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6980</td>\n",
       "      <td>0.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6990</td>\n",
       "      <td>0.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7010</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7020</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7040</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7050</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7060</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7070</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7080</td>\n",
       "      <td>0.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7090</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7110</td>\n",
       "      <td>0.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7120</td>\n",
       "      <td>0.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7130</td>\n",
       "      <td>0.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7140</td>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7150</td>\n",
       "      <td>0.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7160</td>\n",
       "      <td>0.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7170</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7180</td>\n",
       "      <td>0.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7190</td>\n",
       "      <td>0.104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7210</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7220</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7230</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7240</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7260</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7280</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7290</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7310</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7320</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7330</td>\n",
       "      <td>0.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7340</td>\n",
       "      <td>0.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7350</td>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7360</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7370</td>\n",
       "      <td>0.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7380</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7390</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7410</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7420</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7430</td>\n",
       "      <td>0.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7440</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7450</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7460</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7470</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7480</td>\n",
       "      <td>0.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7490</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7510</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7520</td>\n",
       "      <td>0.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7530</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7540</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7550</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7560</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7570</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7580</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7590</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Th1-jpo76ol"
   },
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "\n",
    "class StopOnToken(StoppingCriteria):\n",
    "    def __init__(self, stop_token_id):\n",
    "        self.stop_token_id = stop_token_id\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        return (\n",
    "            self.stop_token_id in input_ids[0]\n",
    "        )\n",
    "\n",
    "\n",
    "stop_token = \"<|end_of_text|>\"\n",
    "stop_token_id = tokenizer.encode(stop_token, add_special_tokens=False)[\n",
    "    0\n",
    "]\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList(\n",
    "    [StopOnToken(stop_token_id)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBrYcpm58CHu",
    "outputId": "eb50a98a-3e87-43ae-e3de-2ea776869740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "How many credit are required to graduate from the Application Development and Delivery program?\n",
      "\n",
      "### Response:\n",
      "The Application Development and Delivery program requires 102 credit to graduate.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            \"How many credit are required to graduate from the Application Development and Delivery program?\",\n",
    "            \"\",\n",
    "        )\n",
    "    ],\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=4096,\n",
    "    stopping_criteria=stopping_criteria\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BR4kjjID8iE3",
    "outputId": "e46ac677-7e1e-4452-9ab3-6009217d19eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What time is class hours for the Application Development and Delivery?\n",
      "\n",
      "### Response:\n",
      "Class hours for the Application Development and Delivery program are 8 am to 6 pm.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            \"What time is class hours for the Application Development and Delivery?\",\n",
    "            \"\",\n",
    "        )\n",
    "    ],\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=4096,\n",
    "    stopping_criteria=stopping_criteria\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPsj9StDecKF",
    "outputId": "3f0450d0-2dc5-4fad-be94-727713a46528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Where is Winnipeg\n",
      "\n",
      "### Response:\n",
      "Winnipeg is located in the Canadian province of Manitoba.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            \"Where is Winnipeg\",\n",
    "            \"\",\n",
    "        )\n",
    "    ],\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=4096,\n",
    "    stopping_criteria=stopping_criteria\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSA6Jk7mfuRZ"
   },
   "outputs": [],
   "source": [
    "base_model = \"unsloth/llama-3-8b-bnb-4bit\"\n",
    "huggingface_token = \"hf_\"\n",
    "huggingface_repo = \"logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it\"\n",
    "save_method = (\n",
    "    \"merged_16bit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681,
     "referenced_widgets": [
      "06e3837a9a8f49c6a13a56807e8b6ea0",
      "14314f1e032d407b9a1c1a99d2a9805b",
      "a33b0e7d2a574f2dbb68233c368701ff",
      "c0578c622b98461cabb93773db85afd7",
      "3b7dac4843c84a1b8218438aafe89b10",
      "4cba5fb18f3848658fbe8ed2ee73ee81",
      "64f10ba503264e8cb1dc9fc225acea2a",
      "d7efa23788624324a0acd1abb4b89dfd",
      "826e1364aad743a4a2b179cd03438ffb",
      "76c5c8a4c8544c59adcf9c46c43ba287",
      "01ea4498cbb64591acbf5d3d235b20e3",
      "68f276ba92804ff691bfb110062da23e",
      "c238a409b5ca4b22ad72703c315b27b1",
      "4d38d192aa9249daa784436f1bda0960",
      "6cd83088d7eb4d369c34c40b62396deb",
      "a84fac09818140b4955776f95c68b862",
      "755a799a76dd4bddb36da606c5002737",
      "0f864a9347d347d193471257751d8110",
      "b1a99842174b4bc2aeb453415b05695d",
      "0327ca8301e64f649071a2cd9b07ddd2",
      "059a11e5aea046b29228757bc5349f0a",
      "34d7b839f91540f59b42f13608eeecdf",
      "35fca615326645a18c278991a6132f93",
      "5b24d39ee55b459380d656038bcd6569",
      "4a1a07a6e883427db96ee7d33f59e5b1",
      "1d0bf37181244f9ca44ca777ecb8e7a4",
      "0fcdf16d80ea4081865e0afb39052416",
      "ea2c4b5c0257479bbe06c45f5edec478",
      "6c45f244a4334af490bfaefd241b7c87",
      "82c9a7af71034bf5aa1a735fd2d068e6",
      "21486557d5d94efeb5baa2a6c3cf3a69",
      "9b9e5c1f0f9c47d1afdc1e27632f5d74",
      "982511b79bfc49a5a50567cf9cb76273",
      "e54594a69b164b37a7bd992c2d83181c",
      "c69467a5e7324ff49791ba6bdd06b820",
      "920b3ecbb99044a4803d0a3004cd01fe",
      "d96eef3fde814a7aab2b791b7edc27fa",
      "068a483a0fe34451a67d794d216174d8",
      "3d5e124f72e04126826f834942ec2dbc",
      "9dd1bebc0c64484ab28fe0d00ecc72f3",
      "82f6ce1e1a144808a4df46c3915b4d88",
      "0bd0f2e5a37a4f0e9a71bec4c8d5b772",
      "626f46b23c304b8b8e35c4d32d58f3e1",
      "f4631bfee4d24d7aba5f31205257e1fc",
      "0003b96558bc405ea5b3b176befc92cc",
      "52c54eb8d55e4978aed37fa1b9a59738",
      "4c881ae396fc455da57a5a7eebca9657",
      "41e60404d4274b81a15df361391bb4f7",
      "54d9a429c03641ec9b7b5ea61cdf6136",
      "a38380260b9d43a0a592545e460f83fe",
      "7f3400e9fa0649c2a264900f00446d08",
      "628c85dbec8e4b40be3c677069df76b6",
      "16278158b2654e47859b6ac98b0c2e43",
      "a7456f4f5dc84529b60e9e26d5864bb8",
      "8f60122db20043db8cb2c838b30ab74c",
      "655eebc9909c4518a494e3d1f7f587f3",
      "556d4a430c9e40e1b8e490756082c5b0",
      "174cb0b480334cd5b707bf15935a40b2",
      "03f90c6a398d453facf65298a288c07d",
      "12ba00ca94574597b1c954a25f090ec7",
      "812b21c8415942198dcd8c529cfa51a4",
      "c4d5b25096044f29a50c2d0f6f6280d3",
      "a580b20a495347aaa7e125e07e0580fe",
      "d0ac104be7c542f281b2c7719c187c45",
      "b7faa033797440a8ae175ab8f6530ff9",
      "f9a124aade8d4cabb341333539601df6",
      "977c11170f1349838e635bcc57fa557c",
      "2c7c0d79f6af4064a0f58a4030fc17d9",
      "eb90fcbd119d4bc9bbeeebb8eff52c07",
      "42f44248737f464c852e75375e8eebec",
      "1fe2ac7e8cba46b2bb1ee8da12848d56",
      "c38405c0cf8a409d91c3f2a1c6c9729c",
      "b394aae3afb9435888a075ff37a036db",
      "7cd45f42a88f4dfcb7252e33ad0c0ea4",
      "5a31665bd4d949ec83a5a72ab5889bec",
      "6b62f11d2345469c972ad781f356278e",
      "a5d87c895e8a4aaaa43c50959552db53",
      "100ae46a75414bdc8e72a63a1a902751",
      "ca31d804e3a64c279faa3e9f41dc028a",
      "e8b952d14f0947b2a6226f0b7ce2aec6",
      "eb54addfa5d74723b2acc83a99b56035",
      "963edc9ea7fa421c917fe430ec78562c",
      "cae25a6aa6a946fb84e186fea84707a0",
      "5d7adeea9bd24a2281383e13688b0042",
      "9a25d94e44414d7db77f2a64ade3fc53",
      "95f49b47198843a996d7e6fcfb3d1a9d",
      "d33af7c94939462cbfbd821f37abb79f",
      "f60dc31781d4462a80f3c4cc08ca0fd5",
      "4134443210ed4cd4ac1775999b8b2eb0",
      "230d15914d6c4ba0ad6b6c4a9c91d2b1",
      "27b93ada822e4203a07429a939fedb36",
      "5c1a96945bce407bbf25f6b3a393c377",
      "038158d4d115466282b7721d4267d3eb",
      "2527f3dd8e9f414398fc9097c9dcb7e3",
      "308f587f626846d59b71e507806fa29c",
      "976287e707bd4771905c8791a49b9ef5",
      "cd4b8e06cc684f20a9283a31d3158dee",
      "f65b0133c163401bb32a52df3d7ab5f4",
      "67bc3249b62e450bb36058e053099cd2",
      "fea4f2ac8afe4e88a94d48e63dd69048",
      "0e6fc3a71eb74eb9aa7cde2c4de5f308",
      "b3f6b04adc644e26b638811020111456",
      "2ad2d7d8769b4435ad8fce7d60a303ab",
      "6db37267ae934318bb65b22b36076f40",
      "249244e196a34ca486ef11618594711e",
      "2b42c07bc1b44e48a5b0337dc226484a",
      "eddd2f47c1e646298c7413e963209ad0",
      "861c77bf013d482088714fc8df86248a",
      "137b968d49c7440eacf2a0ac72e57c18",
      "e80454352fa54b26b4402163b1010daa",
      "6d4680dd84764b0f98aca69d431bde7c",
      "6904f567264c4953a484856780afe5c7",
      "9391449808034d418fd22f37f2d58517",
      "ec8cc422e9e24ddc91f22cb3237651a4",
      "ceb90156543547e2992be1bdeca14374",
      "642c2107607648e59caa064ecb511738",
      "5ef43a6152f74388aba82aac1b56072d",
      "c59a227cc05b4c49b1fd5b9ef3169203",
      "9e292657f77d4d449e62d27d859121f0",
      "314157e77b2b4d6c940f8844163168ec",
      "f6b89c1e3991473fb167e89c5623a4c7",
      "2a3090406b3a45b3b0b98c6d4cf08c39",
      "7d529d3271564cc4b2560b5e904bda8b",
      "e288110afede4d708554fc188c3ae832",
      "c4789241a9824cf78b0c24e49fc2fb36",
      "1d9d3ec0cc4a410397ba0f55f7651be0",
      "ddb5762732aa4df4a2ad8d83018bcdc0",
      "89a4f826527c439f8828568b5e369245",
      "b07740b9d29145a2bab73f8a8f91d4e5",
      "42e43eb43011460fb4857c86055f8871",
      "37b8817493d34b4e9acf45dacc2e181b",
      "7d881ecf3f264b068cd955515788d710",
      "32dc99b56c844e13a906aa327250cad8",
      "7395ca07dce84ceaaf0312cdfb39a975",
      "9d0629dfbbe14b4eb5e26df2927f823a",
      "bde47074262a4b9baab680f2d19a2dce",
      "77b70e1140c846fcb2b0bb98ba6246e2",
      "0fd5d5874a764d3e85997ef1cd0f857d",
      "669d696a242e47ac86bde615d7f3e2ed",
      "e4c9edecf03642b4aa390ace99f826ca",
      "98e2b65438164d7eb28f5f1ffc536cf9",
      "f96d9b656ebb44ceb5dbfd6bb376e087",
      "29c7203473984641bde345d51bdd36b1",
      "b54935c540ce42d0adcce74b3d4ee7fb",
      "57fde989c7f8409eac0285ae28333c8f",
      "7d7e60df6b1d4005933692692e8d1b1e",
      "a0ebebaaa4de4da289bdf7f8b66990b8",
      "9bb24c8b60da4a018dce081aafdf33c7",
      "8f77970be9424582a8d2e3353a35d9a1",
      "e55f2a7cde85467b94cdb3cf90ffc19d",
      "db882df86eeb40f792f11f4bfb889628",
      "4809ccf277424418b7a41973f3eb3152",
      "75a307d3296248acb57914f28722a858",
      "171c1e36103748f4bae9cbf9e53a1533",
      "afdf281f12a0442d9e07adb3300f3bcd",
      "074ca0259b5b41c8acb550c3c7852cc9",
      "59411d3fec9142b6831c74b34f75509d",
      "5aa4445ebcdf436fb67ce421fb153ce9",
      "9196dccaaf4041889eb6b8f460deb0b8",
      "17c348069d6742a39236581b8fe5da1e",
      "498abecb457c4c849d5f78be70254333",
      "b41f1b7b290c4140b03d74fe52681e18",
      "c82c28b1547a4307a69a8b90cd104175",
      "27ec73d76e2e4215ad7625a663429319",
      "62b6bf9471824e6392ed7f0f1cf1094f"
     ]
    },
    "id": "iq2LItH_gnbv",
    "outputId": "3bda7ce3-2af9-4e94-da59-4eac71c75b3b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e3837a9a8f49c6a13a56807e8b6ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f276ba92804ff691bfb110062da23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00004.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Downloading safetensors index for unsloth/llama-3-8b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fca615326645a18c278991a6132f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Merging weights into 16bit:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54594a69b164b37a7bd992c2d83181c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0003b96558bc405ea5b3b176befc92cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655eebc9909c4518a494e3d1f7f587f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Merging weights into 16bit:  25%|       | 1/4 [01:29<04:27, 89.32s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977c11170f1349838e635bcc57fa557c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100ae46a75414bdc8e72a63a1a902751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4134443210ed4cd4ac1775999b8b2eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Merging weights into 16bit:  50%|     | 2/4 [03:04<03:05, 92.73s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea4f2ac8afe4e88a94d48e63dd69048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4680dd84764b0f98aca69d431bde7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3090406b3a45b3b0b98c6d4cf08c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Merging weights into 16bit:  75%|  | 3/4 [04:35<01:32, 92.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dc99b56c844e13a906aa327250cad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54935c540ce42d0adcce74b3d4ee7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdf281f12a0442d9e07adb3300f3bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|| 4/4 [04:59<00:00, 74.82s/it]\n"
     ]
    }
   ],
   "source": [
    "model.push_to_hub_merged(\n",
    "    huggingface_repo,\n",
    "    tokenizer,\n",
    "    save_method=save_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crVzCSNJg5Zp"
   },
   "outputs": [],
   "source": [
    "quantization_method = \"q5_k_m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e6023744d1c04f718a285766f7f2bb2d",
      "8fdb6e36f8af46b6add27355d60d29ba",
      "5f54279dd50e497681c5871678e6a34a",
      "a530f94d6aaa48438211c3b01f823042",
      "d6d46954d9d8467b8fa5fda48c239136",
      "31835f4d12e14189baca420b914d486d",
      "384816bfb53b4541bb451a45ce6745bf",
      "998823428e134e1a96e9d7d9de60f8bc",
      "4beb758a99104345ae2633b67b80c968",
      "78f3114a207e49929fe7ccae5db1e000",
      "fb6af0137fc043a9b6ba18ca7d0cf19a",
      "fcdd1665cf2a422e98f267262de35923",
      "06ec48081d41493ca4dbca9d33e2272f",
      "b5a83be79e584014b4455d8db83387a7",
      "5e5ec82d205e4f83abff1aba32c4eb24",
      "8b26241624784f26a05e3b64deea4f19",
      "c577e3aac2c449cc832d24c6f171e408",
      "276a179d9ee94a20915dc5e702caee26",
      "dc4495a1aef34282ba9e4190c0406071",
      "2b94d945bcfb4e80b8a8053d817ec1bb",
      "2a54752c7a6646f2854938b71b88816e",
      "d8a2cb0c06ef4a3ab0963ba74ccd306d"
     ]
    },
    "id": "5q4cSKPYg6ib",
    "outputId": "320a449d-a542-486b-be78-b1935218a7d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 53.23 out of 83.48 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 32/32 [00:00<00:00, 65.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Done.\n",
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q5_k_m'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
      "Unsloth: [1] Converting model at logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf into bf16 GGUF format.\n",
      "The output location will be /content/logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf/unsloth.BF16.gguf\n",
      "This might take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf\n",
      "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 8192\n",
      "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 32\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:numexpr.utils:NumExpr defaulting to 12 threads.\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128001\n",
      "INFO:gguf.vocab:Setting special token type pad to 128255\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:/content/logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf/unsloth.BF16.gguf: n_tensors = 291, total_size = 16.1G\n",
      "Writing: 100%|| 16.1G/16.1G [01:19<00:00, 201Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to /content/logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf/unsloth.BF16.gguf\n",
      "Unsloth: Conversion completed! Output location: /content/logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf/unsloth.BF16.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q5_k_m. This might take 20 minutes...\n",
      "main: build = 5602 (745aa531)\n",
      "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
      "main: quantizing '/content/logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf/unsloth.BF16.gguf' to '/content/logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf/unsloth.Q5_K_M.gguf' as Q5_K_M using 24 threads\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 291 tensors from /content/logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3 8b Bnb 4bit Rrc District It Q...\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = bnb-4bit-rrc-district-it-gguf\n",
      "llama_model_loader: - kv   4:                           general.basename str              = llama-3\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   6:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   7:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   9:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  10:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  11:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  13:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  14:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  15:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  16:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  17:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  18:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\" \", \" \", \" \", \"...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128255\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type bf16:  226 tensors\n",
      "[   1/ 291]                        output.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n",
      "[   2/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[   3/ 291]                    token_embd.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q5_K .. size =  1002.00 MiB ->   344.44 MiB\n",
      "[   4/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[   5/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[   6/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[   7/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[   8/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[   9/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  10/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  11/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  12/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  13/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  14/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  15/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  16/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  17/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  18/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  19/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  20/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  21/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  22/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  23/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  24/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  25/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  26/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  27/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  29/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  30/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  31/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  32/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  33/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  34/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  35/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  36/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  38/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  39/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  40/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  41/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  42/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  43/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  44/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  45/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  47/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  48/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  49/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  50/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  51/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  52/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  53/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  54/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  56/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  57/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  58/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  59/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  60/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  61/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  62/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  63/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  65/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  66/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  67/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  68/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  69/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  70/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  71/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  72/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  74/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  75/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  76/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  77/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  78/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  79/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  80/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  81/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  83/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  84/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  85/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  86/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  87/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  88/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  89/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  90/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  92/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  93/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[  94/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  95/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  96/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  97/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  98/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  99/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 100/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 101/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 102/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 103/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 104/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 105/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 106/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 107/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 108/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 109/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 110/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 111/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 112/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 113/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 114/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 115/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 116/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 117/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 118/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 119/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 120/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 121/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 122/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 123/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 124/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 125/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 126/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 127/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 128/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 129/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 130/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 131/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 132/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 133/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 134/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 135/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 136/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 137/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 138/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 139/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 140/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 141/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 142/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 143/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 144/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 145/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 146/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 147/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 148/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 149/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 150/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 151/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 152/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 153/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 154/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 155/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 156/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 157/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 158/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 159/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 160/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 161/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 162/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 163/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 164/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 165/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 166/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 167/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 168/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 169/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 170/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 171/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 172/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 173/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 174/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 175/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 176/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 177/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 178/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 179/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 180/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 181/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 182/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 183/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 184/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 185/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 186/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 187/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 188/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 189/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 190/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 191/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 192/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 193/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 194/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 195/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 196/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 197/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 198/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 199/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 200/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 201/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 202/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 203/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 204/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 205/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 206/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 207/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 208/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 210/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 212/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 213/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 214/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 215/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 216/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 217/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 219/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 220/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 221/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 222/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 223/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 224/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 225/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 226/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 227/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 228/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 229/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 230/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 231/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 232/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 233/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 234/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 235/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 236/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 237/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 238/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 239/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 240/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 241/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 242/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 243/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 244/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 245/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 246/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 247/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 248/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 249/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 250/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 251/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 252/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 253/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 254/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 255/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 256/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 257/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 258/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 259/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 260/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 261/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 262/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 263/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 264/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 265/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 266/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 267/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 268/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 269/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 270/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 271/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 272/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 273/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 274/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 275/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 276/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 277/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 278/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 279/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 280/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 281/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 282/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 284/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 285/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 286/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 287/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 288/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 289/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 291/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
      "llama_model_quantize_impl: model size  = 15317.02 MB\n",
      "llama_model_quantize_impl: quant size  =  5459.93 MB\n",
      "\n",
      "main: quantize time = 114758.12 ms\n",
      "main:    total time = 114758.12 ms\n",
      "Unsloth: Conversion completed! Output location: /content/logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf/unsloth.Q5_K_M.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6023744d1c04f718a285766f7f2bb2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdd1665cf2a422e98f267262de35923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q5_K_M.gguf:   0%|          | 0.00/5.73G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/logicalqubit/llama-3-8b-bnb-4bit-rrc-district-it-q5_k_m-gguf\n"
     ]
    }
   ],
   "source": [
    "model.push_to_hub_gguf(\n",
    "    huggingface_repo + \"-q5_k_m-gguf\",\n",
    "    tokenizer,\n",
    "    quantization_method=quantization_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
